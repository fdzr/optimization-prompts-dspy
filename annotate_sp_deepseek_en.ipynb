{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff711e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import dspy\n",
    "\n",
    "from programs import WrapperEnglishSPT, evaluate_answer\n",
    "from custom_evaluation import custom_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175deb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(\n",
    "    \"ollama_chat/deepseek-r1:14b\",\n",
    "    api_base=\"http://localhost:11434\",\n",
    ")\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"test_dwug_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8327c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    examples.append(\n",
    "        dspy.Example(\n",
    "            sentence1=row[\"context_x\"],\n",
    "            sentence2=row[\"context_y\"],\n",
    "            target_word=row[\"lemma\"].split(\"_\")[0],\n",
    "            answer=row[\"judgment\"],\n",
    "        ).with_inputs(\"sentence1\", \"sentence2\", \"target_word\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_spt_prompt_en_assertions = WrapperEnglishSPT().activate_assertions()\n",
    "program_spt_prompt_en_assertions.load(\n",
    "    \"compile-models/sp/en_spt_mipro_optimized_prompt_en_deepseek-q4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6807cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "result = custom_evaluate(\n",
    "    examples,\n",
    "    evaluate_answer,\n",
    "    program_spt_prompt_en_assertions,\n",
    "    report_result=True,\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "print(f\"Elapsed time: {datetime.now() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754878af",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning = [item.reasoning if item else None for item in result]\n",
    "pred = [item.answer if item else None for item in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd35017",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = pd.DataFrame()\n",
    "\n",
    "annotated_data[\"sentence1\"] = data[\"context_x\"].tolist()\n",
    "annotated_data[\"sentence2\"] = data[\"context_y\"].tolist()\n",
    "annotated_data[\"gold_label\"] = [item.answer for item in examples]\n",
    "annotated_data[\"prediction\"] = pred\n",
    "annotated_data[\"reasoning\"] = reasoning\n",
    "annotated_data[\"grouping1\"] = data[\"grouping_x\"].tolist()\n",
    "annotated_data[\"grouping2\"] = data[\"grouping_y\"].tolist()\n",
    "annotated_data[\"identifier1\"] = data[\"identifier1\"].tolist()\n",
    "annotated_data[\"identifier2\"] = data[\"identifier2\"].tolist()\n",
    "annotated_data[\"word\"] = data[\"lemma\"].tolist()\n",
    "annotated_data[\"judgment\"] = data[\"judgment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data.to_csv(\"sp-dwug-en-deepseek.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
