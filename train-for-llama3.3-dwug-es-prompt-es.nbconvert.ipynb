{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2205aa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:30.416401Z",
     "iopub.status.busy": "2025-04-22T20:43:30.416311Z",
     "iopub.status.idle": "2025-04-22T20:43:32.445746Z",
     "shell.execute_reply": "2025-04-22T20:43:32.445486Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Literal, Union\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import MIPROv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from programs import WrapperSpanishSPT, evaluate_answer\n",
    "from custom_evaluation import custom_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4a070c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:32.447658Z",
     "iopub.status.busy": "2025-04-22T20:43:32.447445Z",
     "iopub.status.idle": "2025-04-22T20:43:32.467082Z",
     "shell.execute_reply": "2025-04-22T20:43:32.466881Z"
    }
   },
   "outputs": [],
   "source": [
    "lm = dspy.LM(\n",
    "    \"ollama_chat/llama3.3\",\n",
    "    api_base=\"http://localhost:11434\",\n",
    ")\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f38eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:32.468324Z",
     "iopub.status.busy": "2025-04-22T20:43:32.468144Z",
     "iopub.status.idle": "2025-04-22T20:43:32.484187Z",
     "shell.execute_reply": "2025-04-22T20:43:32.483964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6a767a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:32.485465Z",
     "iopub.status.busy": "2025-04-22T20:43:32.485334Z",
     "iopub.status.idle": "2025-04-22T20:43:32.538097Z",
     "shell.execute_reply": "2025-04-22T20:43:32.537894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8704, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dev_dwug_es.csv\")\n",
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26dc88ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:32.539423Z",
     "iopub.status.busy": "2025-04-22T20:43:32.539220Z",
     "iopub.status.idle": "2025-04-22T20:43:32.714362Z",
     "shell.execute_reply": "2025-04-22T20:43:32.714098Z"
    }
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    training_set.append(\n",
    "        dspy.Example(\n",
    "            sentence1=row[\"context_x\"],\n",
    "            sentence2=row[\"context_y\"],\n",
    "            target_word=row[\"lemma\"],\n",
    "            answer=int(row[\"judgment\"]),\n",
    "        ).with_inputs(\"sentence1\", \"sentence2\", \"target_word\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf95a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:32.715732Z",
     "iopub.status.busy": "2025-04-22T20:43:32.715633Z",
     "iopub.status.idle": "2025-04-22T20:43:32.734186Z",
     "shell.execute_reply": "2025-04-22T20:43:32.733975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406\n",
      "1522\n",
      "2343\n",
      "3433\n",
      "899 282 225\n",
      "973 305 244\n",
      "1499 469 375\n",
      "2196 687 550\n"
     ]
    }
   ],
   "source": [
    "classes_1_es = [item for item in training_set if item.answer == 1]\n",
    "classes_2_es = [item for item in training_set if item.answer == 2]\n",
    "classes_3_es = [item for item in training_set if item.answer == 3]\n",
    "classes_4_es = [item for item in training_set if item.answer == 4]\n",
    "\n",
    "print(len(classes_1_es))\n",
    "print(len(classes_2_es))\n",
    "print(len(classes_3_es))\n",
    "print(len(classes_4_es))\n",
    "\n",
    "classes_1_train, classes_1_dev = train_test_split(\n",
    "    classes_1_es,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "classes_1_train, classes_1_test = train_test_split(\n",
    "    classes_1_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "classes_2_train, classes_2_dev = train_test_split(\n",
    "    classes_2_es,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "classes_2_train, classes_2_test = train_test_split(\n",
    "    classes_2_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "classes_3_train, classes_3_dev = train_test_split(\n",
    "    classes_3_es,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "classes_3_train, classes_3_test = train_test_split(\n",
    "    classes_3_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "classes_4_train, classes_4_dev = train_test_split(\n",
    "    classes_4_es,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "classes_4_train, classes_4_test = train_test_split(\n",
    "    classes_4_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(len(classes_1_train), len(classes_1_dev), len(classes_1_test))\n",
    "print(len(classes_2_train), len(classes_2_dev), len(classes_2_test))\n",
    "print(len(classes_3_train), len(classes_3_dev), len(classes_3_test))\n",
    "print(len(classes_4_train), len(classes_4_dev), len(classes_4_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948e11bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:32.735296Z",
     "iopub.status.busy": "2025-04-22T20:43:32.735171Z",
     "iopub.status.idle": "2025-04-22T20:43:32.748519Z",
     "shell.execute_reply": "2025-04-22T20:43:32.748300Z"
    }
   },
   "outputs": [],
   "source": [
    "program_spt_prompt_es_assertions = WrapperSpanishSPT().activate_assertions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec83586d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T20:43:32.749739Z",
     "iopub.status.busy": "2025-04-22T20:43:32.749573Z",
     "iopub.status.idle": "2025-04-23T02:46:33.621812Z",
     "shell.execute_reply": "2025-04-23T02:46:33.621578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 900 examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate examples: 291\n",
      "Bad-formatted examples: 0\n",
      "Accuracy: 32.333333333333336\n"
     ]
    }
   ],
   "source": [
    "custom_evaluate(\n",
    "    random.choices(classes_1_test, k=225)\n",
    "    + random.choices(classes_2_test, k=225)\n",
    "    + random.choices(classes_3_test, k=225)\n",
    "    + random.choices(classes_4_test, k=225),\n",
    "    evaluate_answer,\n",
    "    program_spt_prompt_es_assertions,\n",
    "    debug=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1cf707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T02:46:33.623057Z",
     "iopub.status.busy": "2025-04-23T02:46:33.622934Z",
     "iopub.status.idle": "2025-04-23T02:46:33.662827Z",
     "shell.execute_reply": "2025-04-23T02:46:33.662633Z"
    }
   },
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "\n",
    "# start_time = datetime.now()\n",
    "\n",
    "# teleprompter = MIPROv2(\n",
    "#     metric=evaluate_answer,\n",
    "#     task_model=lm,\n",
    "#     num_candidates=10,\n",
    "#     init_temperature=0.7,\n",
    "#     max_bootstrapped_demos=3,\n",
    "#     max_labeled_demos=4,\n",
    "#     verbose=False,\n",
    "# )\n",
    "\n",
    "# print(\"Optimizing program with MIPRO...\")\n",
    "# optimized_program = teleprompter.compile(\n",
    "#     program_spt_prompt_es_assertions.deepcopy(),\n",
    "#     trainset=random.choices(classes_1_train, k=500)\n",
    "#     + random.choices(classes_2_train, k=500)\n",
    "#     + random.choices(classes_3_train, k=500)\n",
    "#     + random.choices(classes_4_train, k=500),\n",
    "#     valset=random.choices(classes_1_dev, k=200)\n",
    "#     + random.choices(classes_2_dev, k=200)\n",
    "#     + random.choices(classes_3_dev, k=200)\n",
    "#     + random.choices(classes_4_dev, k=200),\n",
    "#     num_trials=15,\n",
    "#     minibatch_size=25,\n",
    "#     minibatch_full_eval_steps=10,\n",
    "#     minibatch=True,\n",
    "#     requires_permission_to_run=False,\n",
    "# )\n",
    "\n",
    "# optimized_program.save(f\"compile-models/sp/es_spt_mipro_optimized_prompt_es_llama3-3-q4\")\n",
    "\n",
    "# print(f\"Elapsed time: {datetime.now() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85da4b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T02:46:33.664041Z",
     "iopub.status.busy": "2025-04-23T02:46:33.663956Z",
     "iopub.status.idle": "2025-04-23T02:46:33.674445Z",
     "shell.execute_reply": "2025-04-23T02:46:33.674261Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# trial_logs = optimized_program.trial_logs\n",
    "\n",
    "# trial_numbers = list(trial_logs.keys())\n",
    "# scores = [trial_logs[trial][\"score\"] for trial in trial_numbers]\n",
    "\n",
    "# full_eval = [trial_logs[trial][\"full_eval\"] for trial in trial_numbers]\n",
    "\n",
    "# for trial_number, score, pruned in zip(trial_numbers, scores, full_eval):\n",
    "#     if pruned is False:\n",
    "#         plt.scatter(\n",
    "#             trial_number,\n",
    "#             score,\n",
    "#             color=\"grey\",\n",
    "#             label=(\n",
    "#                 \"Pruned Batch\"\n",
    "#                 if \"Pruned Batch\" not in plt.gca().get_legend_handles_labels()[1]\n",
    "#                 else \"\"\n",
    "#             ),\n",
    "#         )\n",
    "#     else:\n",
    "#         plt.scatter(\n",
    "#             trial_number,\n",
    "#             score,\n",
    "#             color=\"green\",\n",
    "#             label=(\n",
    "#                 \"Successful Batch\"\n",
    "#                 if \"Successful Batch\" not in plt.gca().get_legend_handles_labels()[1]\n",
    "#                 else \"\"\n",
    "#             ),\n",
    "#         )\n",
    "\n",
    "# plt.xlabel(\"Batch Number\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.title(\"Batch Scores\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdf9622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T02:46:33.676186Z",
     "iopub.status.busy": "2025-04-23T02:46:33.676015Z",
     "iopub.status.idle": "2025-04-23T02:46:33.685737Z",
     "shell.execute_reply": "2025-04-23T02:46:33.685560Z"
    }
   },
   "outputs": [],
   "source": [
    "# best_score = 0\n",
    "# best_program_so_far = None\n",
    "\n",
    "\n",
    "# def get_signature(predictor):\n",
    "#     if hasattr(predictor, \"extended_signature\"):\n",
    "#         return predictor.extended_signature\n",
    "#     elif hasattr(predictor, \"signature\"):\n",
    "#         return predictor.signature\n",
    "\n",
    "\n",
    "# # print(f\"Baseline program | Score: {best_score}:\")\n",
    "# # for i, predictor in enumerate(WrapperEnglishSPT().predictors()):\n",
    "# #     print(f\"Prompt {i+1} Instruction: {get_signature(predictor).instructions}\")\n",
    "# # print()\n",
    "\n",
    "# print(\"----------------\")\n",
    "\n",
    "# for trial_num in optimized_program.trial_logs:\n",
    "#     program_score = optimized_program.trial_logs[trial_num][\"score\"]\n",
    "#     program_pruned = optimized_program.trial_logs[trial_num][\"full_eval\"]\n",
    "#     # if (\n",
    "#     #     program_score > best_score\n",
    "#     #     and program_pruned is True\n",
    "#     #     # and optimized_program.trial_logs[trial_num][\"full_eval\"]\n",
    "#     # ):\n",
    "#     if program_pruned is True:\n",
    "#         best_score = program_score\n",
    "#         best_program_so_far = optimized_program.trial_logs[trial_num][\"program\"]\n",
    "#     # if trial_num % 5 == 0:\n",
    "#     #     print(f\"Best program after {trial_num} batches | Score: {best_score}:\")\n",
    "#     #     for i, predictor in enumerate(best_program_so_far.predictors()):\n",
    "#     #         print(f\"Prompt {i+1} Instruction: {get_signature(predictor).instructions}\")\n",
    "#     #     print()\n",
    "    \n",
    "#         # print(f\"Best program with best score: {best_score}\")\n",
    "#         for i, predictor in enumerate(best_program_so_far.predictors()):\n",
    "#             print(f\"Prompt {trial_num} Instruction: {get_signature(predictor).instructions}\")\n",
    "#             print(best_score)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33a6383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T02:46:33.686908Z",
     "iopub.status.busy": "2025-04-23T02:46:33.686782Z",
     "iopub.status.idle": "2025-04-23T02:46:33.697216Z",
     "shell.execute_reply": "2025-04-23T02:46:33.697042Z"
    }
   },
   "outputs": [],
   "source": [
    "program_spt_prompt_es_assertions.load(\n",
    "    \"compile-models/sp/es_spt_mipro_optimized_prompt_es_llama3-3-q4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3609a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T02:46:33.698493Z",
     "iopub.status.busy": "2025-04-23T02:46:33.698359Z",
     "iopub.status.idle": "2025-04-23T04:33:32.521628Z",
     "shell.execute_reply": "2025-04-23T04:33:32.521298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 900 examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate examples: 358\n",
      "Bad-formatted examples: 0\n",
      "Accuracy: 39.77777777777778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "custom_evaluate(\n",
    "    random.choices(classes_1_test, k=225)\n",
    "    + random.choices(classes_2_test, k=225)\n",
    "    + random.choices(classes_3_test, k=225)\n",
    "    + random.choices(classes_4_test, k=225),\n",
    "    evaluate_answer,\n",
    "    program_spt_prompt_es_assertions,\n",
    "    debug=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
